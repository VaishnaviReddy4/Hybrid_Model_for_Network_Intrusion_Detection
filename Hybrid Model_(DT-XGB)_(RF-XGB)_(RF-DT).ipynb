{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "5059b293b34a18afd43e6185dfcba4521bd87878"
   },
   "outputs": [],
   "source": [
    "# import relevant modules\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import imblearn\n",
    "import time\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "np.set_printoptions(precision=3)\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2d5309ee0cd9b2f807af7a3ad8a783f066a99d0d"
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "14c15b2699fed6d95c4e3e4de5e4595b4e650920"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/Train_data.csv\")\n",
    "trainB = pd.read_csv(\"../input/Test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "f3ca7cc2b990447e1a401f5b91ba8df21e33c845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25192, 42)\n",
      "Training data has 25192 rows & 42 columns\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "\n",
    "print(\"Training data has {} rows & {} columns\".format(train.shape[0],train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "5ed1bc1c00f047f5fed78fb18100b3be7c3b7852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22544, 41)\n",
      "Testing data has 22544 rows & 41 columns\n"
     ]
    }
   ],
   "source": [
    "print(trainB.shape)\n",
    "\n",
    "print(\"Testing data has {} rows & {} columns\".format(trainB.shape[0],trainB.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bde409f4fe8da1fcb52751bf8c397ac346a2409f"
   },
   "source": [
    "# EXPLORATORY ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "f231cec911b59adb7de03dd877fb38fbc270e09a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_shells</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>num_outbound_cmds</th>\n",
       "      <th>is_host_login</th>\n",
       "      <th>is_guest_login</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>rerror_rate</th>\n",
       "      <th>srv_rerror_rate</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>diff_srv_rate</th>\n",
       "      <th>srv_diff_host_rate</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25192.000000</td>\n",
       "      <td>2.519200e+04</td>\n",
       "      <td>2.519200e+04</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.00000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.0</td>\n",
       "      <td>25192.0</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "      <td>25192.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>305.054104</td>\n",
       "      <td>2.433063e+04</td>\n",
       "      <td>3.491847e+03</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.023738</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.198039</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.394768</td>\n",
       "      <td>0.227850</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.249841</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>84.591180</td>\n",
       "      <td>27.698754</td>\n",
       "      <td>0.286338</td>\n",
       "      <td>0.283762</td>\n",
       "      <td>0.118630</td>\n",
       "      <td>0.120260</td>\n",
       "      <td>0.660559</td>\n",
       "      <td>0.062363</td>\n",
       "      <td>0.095931</td>\n",
       "      <td>182.532074</td>\n",
       "      <td>115.063036</td>\n",
       "      <td>0.519791</td>\n",
       "      <td>0.082539</td>\n",
       "      <td>0.147453</td>\n",
       "      <td>0.031844</td>\n",
       "      <td>0.285800</td>\n",
       "      <td>0.279846</td>\n",
       "      <td>0.117800</td>\n",
       "      <td>0.118769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2686.555640</td>\n",
       "      <td>2.410805e+06</td>\n",
       "      <td>8.883072e+04</td>\n",
       "      <td>0.008910</td>\n",
       "      <td>0.260221</td>\n",
       "      <td>0.00630</td>\n",
       "      <td>2.154202</td>\n",
       "      <td>0.045418</td>\n",
       "      <td>0.488811</td>\n",
       "      <td>10.417352</td>\n",
       "      <td>0.039316</td>\n",
       "      <td>0.048785</td>\n",
       "      <td>11.500842</td>\n",
       "      <td>0.529602</td>\n",
       "      <td>0.018898</td>\n",
       "      <td>0.098524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095115</td>\n",
       "      <td>114.673451</td>\n",
       "      <td>72.468242</td>\n",
       "      <td>0.447312</td>\n",
       "      <td>0.447599</td>\n",
       "      <td>0.318745</td>\n",
       "      <td>0.322335</td>\n",
       "      <td>0.439637</td>\n",
       "      <td>0.178550</td>\n",
       "      <td>0.256583</td>\n",
       "      <td>98.993895</td>\n",
       "      <td>110.646850</td>\n",
       "      <td>0.448944</td>\n",
       "      <td>0.187191</td>\n",
       "      <td>0.308367</td>\n",
       "      <td>0.110575</td>\n",
       "      <td>0.445316</td>\n",
       "      <td>0.446075</td>\n",
       "      <td>0.305869</td>\n",
       "      <td>0.317333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.790000e+02</td>\n",
       "      <td>5.302500e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42862.000000</td>\n",
       "      <td>3.817091e+08</td>\n",
       "      <td>5.151385e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>975.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes          land  wrong_fragment  \\\n",
       "count  25192.000000  2.519200e+04  2.519200e+04  25192.000000    25192.000000   \n",
       "mean     305.054104  2.433063e+04  3.491847e+03      0.000079        0.023738   \n",
       "std     2686.555640  2.410805e+06  8.883072e+04      0.008910        0.260221   \n",
       "min        0.000000  0.000000e+00  0.000000e+00      0.000000        0.000000   \n",
       "25%        0.000000  0.000000e+00  0.000000e+00      0.000000        0.000000   \n",
       "50%        0.000000  4.400000e+01  0.000000e+00      0.000000        0.000000   \n",
       "75%        0.000000  2.790000e+02  5.302500e+02      0.000000        0.000000   \n",
       "max    42862.000000  3.817091e+08  5.151385e+06      1.000000        3.000000   \n",
       "\n",
       "            urgent           hot  num_failed_logins     logged_in  \\\n",
       "count  25192.00000  25192.000000       25192.000000  25192.000000   \n",
       "mean       0.00004      0.198039           0.001191      0.394768   \n",
       "std        0.00630      2.154202           0.045418      0.488811   \n",
       "min        0.00000      0.000000           0.000000      0.000000   \n",
       "25%        0.00000      0.000000           0.000000      0.000000   \n",
       "50%        0.00000      0.000000           0.000000      0.000000   \n",
       "75%        0.00000      0.000000           0.000000      1.000000   \n",
       "max        1.00000     77.000000           4.000000      1.000000   \n",
       "\n",
       "       num_compromised    root_shell  su_attempted      num_root  \\\n",
       "count     25192.000000  25192.000000  25192.000000  25192.000000   \n",
       "mean          0.227850      0.001548      0.001350      0.249841   \n",
       "std          10.417352      0.039316      0.048785     11.500842   \n",
       "min           0.000000      0.000000      0.000000      0.000000   \n",
       "25%           0.000000      0.000000      0.000000      0.000000   \n",
       "50%           0.000000      0.000000      0.000000      0.000000   \n",
       "75%           0.000000      0.000000      0.000000      0.000000   \n",
       "max         884.000000      1.000000      2.000000    975.000000   \n",
       "\n",
       "       num_file_creations    num_shells  num_access_files  num_outbound_cmds  \\\n",
       "count        25192.000000  25192.000000      25192.000000            25192.0   \n",
       "mean             0.014727      0.000357          0.004327                0.0   \n",
       "std              0.529602      0.018898          0.098524                0.0   \n",
       "min              0.000000      0.000000          0.000000                0.0   \n",
       "25%              0.000000      0.000000          0.000000                0.0   \n",
       "50%              0.000000      0.000000          0.000000                0.0   \n",
       "75%              0.000000      0.000000          0.000000                0.0   \n",
       "max             40.000000      1.000000          8.000000                0.0   \n",
       "\n",
       "       is_host_login  is_guest_login         count     srv_count  \\\n",
       "count        25192.0    25192.000000  25192.000000  25192.000000   \n",
       "mean             0.0        0.009130     84.591180     27.698754   \n",
       "std              0.0        0.095115    114.673451     72.468242   \n",
       "min              0.0        0.000000      1.000000      1.000000   \n",
       "25%              0.0        0.000000      2.000000      2.000000   \n",
       "50%              0.0        0.000000     14.000000      8.000000   \n",
       "75%              0.0        0.000000    144.000000     18.000000   \n",
       "max              0.0        1.000000    511.000000    511.000000   \n",
       "\n",
       "        serror_rate  srv_serror_rate   rerror_rate  srv_rerror_rate  \\\n",
       "count  25192.000000     25192.000000  25192.000000     25192.000000   \n",
       "mean       0.286338         0.283762      0.118630         0.120260   \n",
       "std        0.447312         0.447599      0.318745         0.322335   \n",
       "min        0.000000         0.000000      0.000000         0.000000   \n",
       "25%        0.000000         0.000000      0.000000         0.000000   \n",
       "50%        0.000000         0.000000      0.000000         0.000000   \n",
       "75%        1.000000         1.000000      0.000000         0.000000   \n",
       "max        1.000000         1.000000      1.000000         1.000000   \n",
       "\n",
       "       same_srv_rate  diff_srv_rate  srv_diff_host_rate  dst_host_count  \\\n",
       "count   25192.000000   25192.000000        25192.000000    25192.000000   \n",
       "mean        0.660559       0.062363            0.095931      182.532074   \n",
       "std         0.439637       0.178550            0.256583       98.993895   \n",
       "min         0.000000       0.000000            0.000000        0.000000   \n",
       "25%         0.090000       0.000000            0.000000       84.000000   \n",
       "50%         1.000000       0.000000            0.000000      255.000000   \n",
       "75%         1.000000       0.060000            0.000000      255.000000   \n",
       "max         1.000000       1.000000            1.000000      255.000000   \n",
       "\n",
       "       dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count        25192.000000            25192.000000            25192.000000   \n",
       "mean           115.063036                0.519791                0.082539   \n",
       "std            110.646850                0.448944                0.187191   \n",
       "min              0.000000                0.000000                0.000000   \n",
       "25%             10.000000                0.050000                0.000000   \n",
       "50%             61.000000                0.510000                0.030000   \n",
       "75%            255.000000                1.000000                0.070000   \n",
       "max            255.000000                1.000000                1.000000   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                 25192.000000                 25192.000000   \n",
       "mean                      0.147453                     0.031844   \n",
       "std                       0.308367                     0.110575   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.060000                     0.020000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count          25192.000000              25192.000000          25192.000000   \n",
       "mean               0.285800                  0.279846              0.117800   \n",
       "std                0.445316                  0.446075              0.305869   \n",
       "min                0.000000                  0.000000              0.000000   \n",
       "25%                0.000000                  0.000000              0.000000   \n",
       "50%                0.000000                  0.000000              0.000000   \n",
       "75%                1.000000                  1.000000              0.000000   \n",
       "max                1.000000                  1.000000              1.000000   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "count              25192.000000  \n",
       "mean                   0.118769  \n",
       "std                    0.317333  \n",
       "min                    0.000000  \n",
       "25%                    0.000000  \n",
       "50%                    0.000000  \n",
       "75%                    0.000000  \n",
       "max                    1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive statistics\n",
    "train.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_shells</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>num_outbound_cmds</th>\n",
       "      <th>is_host_login</th>\n",
       "      <th>is_guest_login</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>rerror_rate</th>\n",
       "      <th>srv_rerror_rate</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>diff_srv_rate</th>\n",
       "      <th>srv_diff_host_rate</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22544.000000</td>\n",
       "      <td>2.254400e+04</td>\n",
       "      <td>2.254400e+04</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.0</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "      <td>22544.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>218.859076</td>\n",
       "      <td>1.039545e+04</td>\n",
       "      <td>2.056019e+03</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.008428</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.105394</td>\n",
       "      <td>0.021647</td>\n",
       "      <td>0.442202</td>\n",
       "      <td>0.119899</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.114665</td>\n",
       "      <td>0.008738</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.028433</td>\n",
       "      <td>79.028345</td>\n",
       "      <td>31.124379</td>\n",
       "      <td>0.102924</td>\n",
       "      <td>0.103635</td>\n",
       "      <td>0.238463</td>\n",
       "      <td>0.235179</td>\n",
       "      <td>0.740345</td>\n",
       "      <td>0.094074</td>\n",
       "      <td>0.098110</td>\n",
       "      <td>193.869411</td>\n",
       "      <td>140.750532</td>\n",
       "      <td>0.608722</td>\n",
       "      <td>0.090540</td>\n",
       "      <td>0.132261</td>\n",
       "      <td>0.019638</td>\n",
       "      <td>0.097814</td>\n",
       "      <td>0.099426</td>\n",
       "      <td>0.233385</td>\n",
       "      <td>0.226683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1407.176612</td>\n",
       "      <td>4.727864e+05</td>\n",
       "      <td>2.121930e+04</td>\n",
       "      <td>0.017619</td>\n",
       "      <td>0.142599</td>\n",
       "      <td>0.036473</td>\n",
       "      <td>0.928428</td>\n",
       "      <td>0.150328</td>\n",
       "      <td>0.496659</td>\n",
       "      <td>7.269597</td>\n",
       "      <td>0.049334</td>\n",
       "      <td>0.021060</td>\n",
       "      <td>8.041614</td>\n",
       "      <td>0.676842</td>\n",
       "      <td>0.048014</td>\n",
       "      <td>0.067829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022084</td>\n",
       "      <td>0.166211</td>\n",
       "      <td>128.539248</td>\n",
       "      <td>89.062532</td>\n",
       "      <td>0.295367</td>\n",
       "      <td>0.298332</td>\n",
       "      <td>0.416118</td>\n",
       "      <td>0.416215</td>\n",
       "      <td>0.412496</td>\n",
       "      <td>0.259138</td>\n",
       "      <td>0.253545</td>\n",
       "      <td>94.035663</td>\n",
       "      <td>111.783972</td>\n",
       "      <td>0.435688</td>\n",
       "      <td>0.220717</td>\n",
       "      <td>0.306268</td>\n",
       "      <td>0.085394</td>\n",
       "      <td>0.273139</td>\n",
       "      <td>0.281866</td>\n",
       "      <td>0.387229</td>\n",
       "      <td>0.400875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>4.600000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.870000e+02</td>\n",
       "      <td>6.010000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>123.250000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>57715.000000</td>\n",
       "      <td>6.282565e+07</td>\n",
       "      <td>1.345927e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>796.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes          land  wrong_fragment  \\\n",
       "count  22544.000000  2.254400e+04  2.254400e+04  22544.000000    22544.000000   \n",
       "mean     218.859076  1.039545e+04  2.056019e+03      0.000311        0.008428   \n",
       "std     1407.176612  4.727864e+05  2.121930e+04      0.017619        0.142599   \n",
       "min        0.000000  0.000000e+00  0.000000e+00      0.000000        0.000000   \n",
       "25%        0.000000  0.000000e+00  0.000000e+00      0.000000        0.000000   \n",
       "50%        0.000000  5.400000e+01  4.600000e+01      0.000000        0.000000   \n",
       "75%        0.000000  2.870000e+02  6.010000e+02      0.000000        0.000000   \n",
       "max    57715.000000  6.282565e+07  1.345927e+06      1.000000        3.000000   \n",
       "\n",
       "             urgent           hot  num_failed_logins     logged_in  \\\n",
       "count  22544.000000  22544.000000       22544.000000  22544.000000   \n",
       "mean       0.000710      0.105394           0.021647      0.442202   \n",
       "std        0.036473      0.928428           0.150328      0.496659   \n",
       "min        0.000000      0.000000           0.000000      0.000000   \n",
       "25%        0.000000      0.000000           0.000000      0.000000   \n",
       "50%        0.000000      0.000000           0.000000      0.000000   \n",
       "75%        0.000000      0.000000           0.000000      1.000000   \n",
       "max        3.000000    101.000000           4.000000      1.000000   \n",
       "\n",
       "       num_compromised    root_shell  su_attempted      num_root  \\\n",
       "count     22544.000000  22544.000000  22544.000000  22544.000000   \n",
       "mean          0.119899      0.002440      0.000266      0.114665   \n",
       "std           7.269597      0.049334      0.021060      8.041614   \n",
       "min           0.000000      0.000000      0.000000      0.000000   \n",
       "25%           0.000000      0.000000      0.000000      0.000000   \n",
       "50%           0.000000      0.000000      0.000000      0.000000   \n",
       "75%           0.000000      0.000000      0.000000      0.000000   \n",
       "max         796.000000      1.000000      2.000000    878.000000   \n",
       "\n",
       "       num_file_creations    num_shells  num_access_files  num_outbound_cmds  \\\n",
       "count        22544.000000  22544.000000      22544.000000            22544.0   \n",
       "mean             0.008738      0.001153          0.003549                0.0   \n",
       "std              0.676842      0.048014          0.067829                0.0   \n",
       "min              0.000000      0.000000          0.000000                0.0   \n",
       "25%              0.000000      0.000000          0.000000                0.0   \n",
       "50%              0.000000      0.000000          0.000000                0.0   \n",
       "75%              0.000000      0.000000          0.000000                0.0   \n",
       "max            100.000000      5.000000          4.000000                0.0   \n",
       "\n",
       "       is_host_login  is_guest_login         count     srv_count  \\\n",
       "count   22544.000000    22544.000000  22544.000000  22544.000000   \n",
       "mean        0.000488        0.028433     79.028345     31.124379   \n",
       "std         0.022084        0.166211    128.539248     89.062532   \n",
       "min         0.000000        0.000000      0.000000      0.000000   \n",
       "25%         0.000000        0.000000      1.000000      1.000000   \n",
       "50%         0.000000        0.000000      8.000000      6.000000   \n",
       "75%         0.000000        0.000000    123.250000     16.000000   \n",
       "max         1.000000        1.000000    511.000000    511.000000   \n",
       "\n",
       "        serror_rate  srv_serror_rate   rerror_rate  srv_rerror_rate  \\\n",
       "count  22544.000000     22544.000000  22544.000000     22544.000000   \n",
       "mean       0.102924         0.103635      0.238463         0.235179   \n",
       "std        0.295367         0.298332      0.416118         0.416215   \n",
       "min        0.000000         0.000000      0.000000         0.000000   \n",
       "25%        0.000000         0.000000      0.000000         0.000000   \n",
       "50%        0.000000         0.000000      0.000000         0.000000   \n",
       "75%        0.000000         0.000000      0.250000         0.072500   \n",
       "max        1.000000         1.000000      1.000000         1.000000   \n",
       "\n",
       "       same_srv_rate  diff_srv_rate  srv_diff_host_rate  dst_host_count  \\\n",
       "count   22544.000000   22544.000000        22544.000000    22544.000000   \n",
       "mean        0.740345       0.094074            0.098110      193.869411   \n",
       "std         0.412496       0.259138            0.253545       94.035663   \n",
       "min         0.000000       0.000000            0.000000        0.000000   \n",
       "25%         0.250000       0.000000            0.000000      121.000000   \n",
       "50%         1.000000       0.000000            0.000000      255.000000   \n",
       "75%         1.000000       0.060000            0.000000      255.000000   \n",
       "max         1.000000       1.000000            1.000000      255.000000   \n",
       "\n",
       "       dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count        22544.000000            22544.000000            22544.000000   \n",
       "mean           140.750532                0.608722                0.090540   \n",
       "std            111.783972                0.435688                0.220717   \n",
       "min              0.000000                0.000000                0.000000   \n",
       "25%             15.000000                0.070000                0.000000   \n",
       "50%            168.000000                0.920000                0.010000   \n",
       "75%            255.000000                1.000000                0.060000   \n",
       "max            255.000000                1.000000                1.000000   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                 22544.000000                 22544.000000   \n",
       "mean                      0.132261                     0.019638   \n",
       "std                       0.306268                     0.085394   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.030000                     0.010000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count          22544.000000              22544.000000          22544.000000   \n",
       "mean               0.097814                  0.099426              0.233385   \n",
       "std                0.273139                  0.281866              0.387229   \n",
       "min                0.000000                  0.000000              0.000000   \n",
       "25%                0.000000                  0.000000              0.000000   \n",
       "50%                0.000000                  0.000000              0.000000   \n",
       "75%                0.000000                  0.000000              0.360000   \n",
       "max                1.000000                  1.000000              1.000000   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "count              22544.000000  \n",
       "mean                   0.226683  \n",
       "std                    0.400875  \n",
       "min                    0.000000  \n",
       "25%                    0.000000  \n",
       "50%                    0.000000  \n",
       "75%                    0.170000  \n",
       "max                    1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainB.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "06b94b1d1a0c6ba604a7d69c1495132c3f38710c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    25192\n",
      "Name: num_outbound_cmds, dtype: int64\n",
      "0    22544\n",
      "Name: num_outbound_cmds, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['num_outbound_cmds'].value_counts())\n",
    "print(trainB['num_outbound_cmds'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "4e0f8a1adcd11b17c9bda454c8c29e486ac10f64"
   },
   "outputs": [],
   "source": [
    "#'num_outbound_cmds' is a redundant column so remove it from both train & test datasets\n",
    "train.drop(['num_outbound_cmds'], axis=1, inplace=True)\n",
    "trainB.drop(['num_outbound_cmds'], axis=1, inplace=True)\n",
    "train.drop(['dst_host_srv_count'],axis=1, inplace =True)\n",
    "trainB.drop(['dst_host_srv_count'],axis=1, inplace =True)\n",
    "train.drop(['src_bytes'],axis=1, inplace =True)\n",
    "trainB.drop(['src_bytes'],axis=1, inplace =True)\n",
    "train.drop(['flag'],axis=1, inplace =True)\n",
    "trainB.drop(['flag'],axis=1, inplace =True)\n",
    "train.drop(['dst_bytes'],axis=1, inplace =True)\n",
    "trainB.drop(['dst_bytes'],axis=1, inplace =True)\n",
    "train.drop(['same_srv_rate'],axis=1, inplace =True)\n",
    "trainB.drop(['same_srv_rate'],axis=1, inplace =True)\n",
    "train.drop(['dst_host_same_srv_rate'],axis=1, inplace =True)\n",
    "trainB.drop(['dst_host_same_srv_rate'],axis=1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "df0fc1cc89e3a82a7b07e1662c99abf42deddbc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal     13449\n",
       "anomaly    11743\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attack Class Distribution\n",
    "train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d472d5c2705a8d322b20fa1994139a4c9cdaebce"
   },
   "source": [
    "# SCALING NUMERICAL ATTRIBUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "654b1e6dfb83362b836ed892df4deae0d48ce4b0"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# extract numerical attributes and scale it to have zero mean and unit variance  \n",
    "cols = train.select_dtypes(include=['float64','int64']).columns\n",
    "sc_train = scaler.fit_transform(train.select_dtypes(include=['float64','int64']))\n",
    "sc_trainB = scaler.fit_transform(trainB.select_dtypes(include=['float64','int64']))\n",
    "\n",
    "# turn the result back to a dataframe\n",
    "sc_traindf = pd.DataFrame(sc_train, columns = cols)\n",
    "sc_trainBdf = pd.DataFrame(sc_trainB, columns = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bd7451b8802bfb2201a978469b0636d082aa3a0a"
   },
   "source": [
    "# ENCODING CATEGORICAL ATTRIBUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "e3d637225809dfcc6aa3ea7ef4a9b1d55d2b436c"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# extract categorical attributes from both training and test sets \n",
    "cattrain = train.select_dtypes(include=['object']).copy()\n",
    "cattrainB = trainB.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# encode the categorical attributes\n",
    "traincat = cattrain.apply(encoder.fit_transform)\n",
    "trainBcat = cattrainB.apply(encoder.fit_transform)\n",
    "\n",
    "# separate target column from encoded data \n",
    "enctrain = traincat.drop(['class'], axis=1)\n",
    "cat_Ytrain = traincat[['class']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "227915d0f6d7a22ec344d4a016049acecb0323f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25192, 34)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cols = train.select_dtypes(include=['float64','int64']).columns\n",
    "#colval = train.select_dtypes(include=['float64','int64'])\n",
    "#sc_traindf = pd.DataFrame(colval, columns = cols)\n",
    "train_x = pd.concat([sc_traindf,enctrain],axis=1)\n",
    "train_y = train['class']\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "ca90e6da174743f665a1fc640ff3070e502a3535"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 34)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cols = test.select_dtypes(include=['float64','int64']).columns\n",
    "#colval = test.select_dtypes(include=['float64','int64'])\n",
    "#sc_traindf = pd.DataFrame(colval, columns = cols)\n",
    "trainB_df = pd.concat([sc_trainBdf,trainBcat],axis=1)\n",
    "\n",
    "trainB_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58212e80c11969c02f35adbf42d2bba7881dfde0"
   },
   "source": [
    "# FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "6608ad7beebd4cd2ca3cbc0999da5def00d0c4e5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier();\n",
    "\n",
    "# fit random forest classifier on the training set\n",
    "rfc.fit(train_x, train_y);\n",
    "# extract important features\n",
    "score = np.round(rfc.feature_importances_,3)\n",
    "importances = pd.DataFrame({'feature':train_x.columns,'importance':score})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "# plot importances\n",
    "plt.rcParams['figure.figsize'] = (11, 4)\n",
    "importances.plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "4d9cffa96fadfddb552370e614d3e9ccc7a2c420"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "import itertools\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# create the RFE model and select 10 attributes\n",
    "rfe = RFE(rfc, n_features_to_select=15)\n",
    "rfe = rfe.fit(train_x, train_y)\n",
    "\n",
    "# summarize the selection of the attributes\n",
    "feature_map = [(i, v) for i, v in itertools.zip_longest(rfe.get_support(), train_x.columns)]\n",
    "selected_features = [v for i, v in feature_map if i==True]\n",
    "\n",
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c20a81752c216722f4fdfb8ce2837956823c1b6d"
   },
   "source": [
    "# DATASET PARTITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "6a5e5c54d8c5d760085d104bdc8c5eb44b6372b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10076, 34) (10076,)\n",
      "(10077, 34) (10077,)\n",
      "(2519, 34) (2519,)\n",
      "(2520, 34) (2520,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#train_x= train_x[selected_features]\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(train_x,train_y,train_size=0.80, random_state=35)\n",
    "X_train,X_trainB,Y_train,Y_trainB = train_test_split(X_train,Y_train,train_size=0.50, random_state=25)\n",
    "X_test,X_testB,Y_test,Y_testB = train_test_split(X_test,Y_test,train_size=0.50, random_state=25)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_trainB.shape, Y_trainB.shape)\n",
    "print(X_test.shape, Y_test.shape)\n",
    "print(X_testB.shape, Y_testB.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb80c25403d2e9030d20e37eefa4d54c83dfb056"
   },
   "source": [
    "# FITTING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "9ab0f6c11f8772d9f1c008ee2b4d1f181af3effb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time for Decision Tree:  0.05311012268066406\n",
      "\n",
      "Training time for XGBoost:  0.11339807510375977\n",
      "\n",
      "Training time for Random Forest:  0.028948068618774414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\"\"\"\n",
    "# Train KNeighborsClassifier Model\n",
    "KNN_Classifier = KNeighborsClassifier(n_jobs=-1)\n",
    "KNN_Classifier.fit(X_train, Y_train); \n",
    "\n",
    "# Train LogisticRegression Model\n",
    "LGR_Classifier = LogisticRegression(n_jobs=-1, random_state=0)\n",
    "LGR_Classifier.fit(X_train, Y_train);\n",
    "\"\"\"\n",
    "# Train Gaussian Naive Baye Model\n",
    "BNB_Classifier = BernoulliNB()\n",
    "BNB_Classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Train Decision Tree Model\n",
    "t1=time.time()\n",
    "DTC_Classifier = tree.DecisionTreeClassifier(criterion='gini',max_depth=2, random_state=10)\n",
    "DTC_Classifier.fit(X_train, Y_train)\n",
    "t2=time.time()\n",
    "print(\"Training time for Decision Tree: \", t2-t1)\n",
    "print()\n",
    "\n",
    "t1=time.time()\n",
    "XGB_Classifier = XGBClassifier(base_score=0.3, n_estimators=5)\n",
    "XGB_Classifier.fit(X_train, Y_train)\n",
    "t2=time.time()\n",
    "print(\"Training time for XGBoost: \", t2-t1)\n",
    "print()\n",
    "\n",
    "t1=time.time()\n",
    "RandomForest_Classifier = RandomForestClassifier(n_estimators=1)\n",
    "RandomForest_Classifier.fit(X_train, Y_train)\n",
    "t2=time.time()\n",
    "print(\"Training time for Random Forest: \", t2-t1)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9753eed4eab0e0587d016b78efce930aa782f29f"
   },
   "source": [
    "# EVALUATE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "56a6d972dfc7236bddc02b254416331a45e1b57a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Naive Baye Classifier Model Evaluation ==============================\n",
      "\n",
      "Cross Validation Mean Score:\n",
      " 0.8955947713006435\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9027391822151647\n",
      "\n",
      "Confusion matrix:\n",
      " [[1012  175]\n",
      " [  70 1262]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly  0.93530499 0.85256950 0.89202292      1187\n",
      "      normal  0.87821851 0.94744745 0.91152040      1332\n",
      "\n",
      "   micro avg  0.90273918 0.90273918 0.90273918      2519\n",
      "   macro avg  0.90676175 0.90000848 0.90177166      2519\n",
      "weighted avg  0.90511873 0.90273918 0.90233282      2519\n",
      "\n",
      "\n",
      "\n",
      "============================== Decision Tree Classifier Model Evaluation ==============================\n",
      "\n",
      "Cross Validation Mean Score:\n",
      " 0.9257630998060584\n",
      "\n",
      "Model Accuracy:\n",
      " 0.925764192139738\n",
      "\n",
      "Confusion matrix:\n",
      " [[1018  169]\n",
      " [  18 1314]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly  0.98262548 0.85762426 0.91587944      1187\n",
      "      normal  0.88604181 0.98648649 0.93357016      1332\n",
      "\n",
      "   micro avg  0.92576419 0.92576419 0.92576419      2519\n",
      "   macro avg  0.93433364 0.92205537 0.92472480      2519\n",
      "weighted avg  0.93155384 0.92576419 0.92523396      2519\n",
      "\n",
      "\n",
      "\n",
      "============================== XG Boost Classifier Model Evaluation ==============================\n",
      "\n",
      "Cross Validation Mean Score:\n",
      " 0.9340997950603009\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9587137753076618\n",
      "\n",
      "Confusion matrix:\n",
      " [[1124   63]\n",
      " [  41 1291]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly  0.96480687 0.94692502 0.95578231      1187\n",
      "      normal  0.95347120 0.96921922 0.96128071      1332\n",
      "\n",
      "   micro avg  0.95871378 0.95871378 0.95871378      2519\n",
      "   macro avg  0.95913903 0.95807212 0.95853151      2519\n",
      "weighted avg  0.95881278 0.95871378 0.95868976      2519\n",
      "\n",
      "\n",
      "\n",
      "============================== Random Forest Classifier Model Evaluation ==============================\n",
      "\n",
      "Cross Validation Mean Score:\n",
      " 0.9781633863567001\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9896784438269154\n",
      "\n",
      "Confusion matrix:\n",
      " [[1177   10]\n",
      " [  16 1316]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly  0.98658843 0.99157540 0.98907563      1187\n",
      "      normal  0.99245852 0.98798799 0.99021821      1332\n",
      "\n",
      "   micro avg  0.98967844 0.98967844 0.98967844      2519\n",
      "   macro avg  0.98952348 0.98978169 0.98964692      2519\n",
      "weighted avg  0.98969243 0.98967844 0.98967980      2519\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "models = []\n",
    "models.append(('Naive Baye Classifier', BNB_Classifier))\n",
    "models.append(('Decision Tree Classifier', DTC_Classifier))\n",
    "models.append(('XG Boost Classifier', XGB_Classifier))\n",
    "models.append(('Random Forest Classifier', RandomForest_Classifier))\n",
    "\n",
    "\n",
    "\n",
    "for i, v in models:\n",
    "    scores = cross_val_score(v, X_test, Y_test, cv=10)\n",
    "    accuracy = metrics.accuracy_score(Y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(Y_test, v.predict(X_test))\n",
    "    classification = metrics.classification_report(Y_test, v.predict(X_test), digits=8)\n",
    "    print()\n",
    "    print('============================== {} Model Evaluation =============================='.format(i))\n",
    "    print()\n",
    "    print (\"Cross Validation Mean Score:\" \"\\n\", scores.mean())\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "304fddb4f81dbe6893caf007ffdde527243fa119"
   },
   "source": [
    "# VALIDATING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "5ab78f517053e419f6c6667e90a0b352ccb5f531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Naive Baye Classifier Model Test Results ==============================\n",
      "\n",
      "Prediction time of  Naive Baye Classifier 0.012201786041259766\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9027391822151647\n",
      "\n",
      "Confusion matrix:\n",
      " [[1012  175]\n",
      " [  70 1262]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       0.94      0.85      0.89      1187\n",
      "      normal       0.88      0.95      0.91      1332\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2519\n",
      "   macro avg       0.91      0.90      0.90      2519\n",
      "weighted avg       0.91      0.90      0.90      2519\n",
      "\n",
      "\n",
      "\n",
      "============================== Decision Tree Classifier Model Test Results ==============================\n",
      "\n",
      "Prediction time of  Decision Tree Classifier 0.012695550918579102\n",
      "\n",
      "Model Accuracy:\n",
      " 0.925764192139738\n",
      "\n",
      "Confusion matrix:\n",
      " [[1018  169]\n",
      " [  18 1314]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       0.98      0.86      0.92      1187\n",
      "      normal       0.89      0.99      0.93      1332\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      2519\n",
      "   macro avg       0.93      0.92      0.92      2519\n",
      "weighted avg       0.93      0.93      0.93      2519\n",
      "\n",
      "\n",
      "\n",
      "============================== XG Boost Classifier Model Test Results ==============================\n",
      "\n",
      "Prediction time of  XG Boost Classifier 0.013476848602294922\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9587137753076618\n",
      "\n",
      "Confusion matrix:\n",
      " [[1124   63]\n",
      " [  41 1291]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       0.96      0.95      0.96      1187\n",
      "      normal       0.95      0.97      0.96      1332\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2519\n",
      "   macro avg       0.96      0.96      0.96      2519\n",
      "weighted avg       0.96      0.96      0.96      2519\n",
      "\n",
      "\n",
      "\n",
      "============================== Random Forest Classifier Model Test Results ==============================\n",
      "\n",
      "Prediction time of  Random Forest Classifier 0.013508319854736328\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9896784438269154\n",
      "\n",
      "Confusion matrix:\n",
      " [[1177   10]\n",
      " [  16 1316]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       0.99      0.99      0.99      1187\n",
      "      normal       0.99      0.99      0.99      1332\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      2519\n",
      "   macro avg       0.99      0.99      0.99      2519\n",
      "weighted avg       0.99      0.99      0.99      2519\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, v in models:\n",
    "    t1=time.time()\n",
    "    accuracy = metrics.accuracy_score(Y_test, v.predict(X_test))\n",
    "    t2=time.time()\n",
    "    confusion_matrix = metrics.confusion_matrix(Y_test, v.predict(X_test))\n",
    "    classification = metrics.classification_report(Y_test, v.predict(X_test))\n",
    "    print()\n",
    "    print('============================== {} Model Test Results =============================='.format(i))\n",
    "    print()\n",
    "    print(\"Prediction time of \", i, t2-t1)\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to extract locations of FP, FN as a pandas series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To generate the last row after NB prediction function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genPredRow(y_actual, y_pred):\n",
    "    FP = []\n",
    "\n",
    "    for i in range(len(y_pred)): \n",
    "        if y_pred[i]=='anomaly' and y_actual.iat[i]!=y_pred[i]:\n",
    "           FP.append(1)\n",
    "        elif y_pred[i]=='normal' and y_actual.iat[i]!=y_pred[i]:\n",
    "           FP.append(1) \n",
    "        else:\n",
    "            FP.append(0)\n",
    "    return (pd.Series(FP))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Decision Tree and XG Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting FP and FN row location from NB output as pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of number of FP: 10077\n",
      "(10077, 35)\n",
      "(2520, 34)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"models = []\n",
    "models.append(('Naive Baye Classifier', BNB_Classifier))\n",
    "models.append(('Decision Tree Classifier', DTC_Classifier))\n",
    "models.append(('XG Boost Classifier', XGB_Classifier))\n",
    "models.append(('Random Forest Classifier', RandomForest_Classifier))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "t1= time.time()\n",
    "\n",
    "##USING DECISION TREE TO PREDICT PREVIOUS VALUES\n",
    "X_testB_XGB_DCT = X_testB.copy()\n",
    "Y_testB_XGB_DCT = Y_testB.copy()\n",
    "X_trainB_XGB_DCT = X_trainB.copy()\n",
    "Y_trainB_XGB_DCT = Y_trainB.copy()\n",
    "finalPred= genPredRow(Y_trainB_XGB_DCT, models[1][1].predict(X_trainB_XGB_DCT))\n",
    "print(\"Size of number of FP:\", finalPred.size) \n",
    "\n",
    "finalPredTest = genPredRow(Y_testB_XGB_DCT, models[1][1].predict(X_testB_XGB_DCT))\n",
    "\n",
    "X_trainB_XGB_DCT['prevPred'] = np.array(finalPred)\n",
    "X_testB_XGB_DCT['prevPred'] = np.array(finalPredTest)\n",
    "print(X_trainB_XGB_DCT.shape)\n",
    "print(X_testB.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASSING X_TRAIN B TO TRAIN XGBOOST \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Time for Decision Tree and XG Boost:  0.2317490577697754\n"
     ]
    }
   ],
   "source": [
    "XGB_Classifier_DCT = XGBClassifier(base_score=0.3, n_estimators=5)\n",
    "XGB_Classifier_DCT.fit(X_trainB_XGB_DCT, Y_trainB_XGB_DCT)\n",
    "print()\n",
    "\n",
    "t2=time.time()\n",
    "print (\"Training Time for Decision Tree and XG Boost: \", t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing new XG Boost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Time for Decision Tree and XG Boost:  0.00521087646484375\n",
      "\n",
      "\n",
      "============================== Decision tree + XG Boost Model Evaluation ==============================\n",
      "\n",
      "Cross Validation Mean Score:\n",
      " 0.9912713222647399\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9940476190476191\n",
      "\n",
      "Confusion matrix:\n",
      " [[1177    0]\n",
      " [  15 1328]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly  0.98741611 1.00000000 0.99366821      1177\n",
      "      normal  1.00000000 0.98883098 0.99438413      1343\n",
      "\n",
      "   micro avg  0.99404762 0.99404762 0.99404762      2520\n",
      "   macro avg  0.99370805 0.99441549 0.99402617      2520\n",
      "weighted avg  0.99412252 0.99404762 0.99404975      2520\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "Y_testB_XGB_DCT_pred = XGB_Classifier_DCT.predict(X_testB_XGB_DCT)\n",
    "t2=time.time()\n",
    "print (\"Prediction Time for Decision Tree and XG Boost: \", t2-t1)\n",
    "print()\n",
    "scores_XGB_DCT = cross_val_score(XGB_Classifier_DCT, X_testB_XGB_DCT, Y_testB_XGB_DCT, cv=10)\n",
    "accuracy_XGB_DCT = metrics.accuracy_score(Y_testB_XGB_DCT, Y_testB_XGB_DCT_pred)\n",
    "confusion_matrix_XGB_DCT = metrics.confusion_matrix(Y_testB_XGB_DCT,Y_testB_XGB_DCT_pred)\n",
    "classification_XGB_DCT = metrics.classification_report(Y_testB_XGB_DCT,Y_testB_XGB_DCT_pred, digits=8)\n",
    "print()\n",
    "print('============================== {} Model Evaluation =============================='.format('Decision tree + XG Boost'))\n",
    "print()\n",
    "print (\"Cross Validation Mean Score:\" \"\\n\", scores_XGB_DCT.mean())\n",
    "print()\n",
    "print (\"Model Accuracy:\" \"\\n\", accuracy_XGB_DCT)\n",
    "print()\n",
    "print(\"Confusion matrix:\" \"\\n\", confusion_matrix_XGB_DCT)\n",
    "print()\n",
    "print(\"Classification report:\" \"\\n\", classification_XGB_DCT) \n",
    "print()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Random Forest with XG BOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of number of FP: 10077\n",
      "(10077, 35)\n",
      "(2520, 34)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"models = []\n",
    "models.append(('Naive Baye Classifier', BNB_Classifier))\n",
    "models.append(('Decision Tree Classifier', DTC_Classifier))\n",
    "models.append(('XG Boost Classifier', XGB_Classifier))\n",
    "models.append(('Random Forest Classifier', RandomForest_Classifier))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "t1=time.time()\n",
    "##USING DECISION TREE TO PREDICT PREVIOUS VALUES\n",
    "X_testB_XGB_RF = X_testB.copy()\n",
    "Y_testB_XGB_RF = Y_testB.copy()\n",
    "X_trainB_XGB_RF = X_trainB.copy()\n",
    "Y_trainB_XGB_RF = Y_trainB.copy()\n",
    "finalPred= genPredRow(Y_trainB_XGB_RF, models[1][1].predict(X_trainB_XGB_RF))\n",
    "print(\"Size of number of FP:\", finalPred.size) \n",
    "\n",
    "finalPredTest = genPredRow(Y_testB_XGB_RF, models[1][1].predict(X_testB_XGB_RF))\n",
    "\n",
    "X_trainB_XGB_RF['prevPred'] = np.array(finalPred)\n",
    "X_testB_XGB_RF['prevPred'] = np.array(finalPredTest)\n",
    "print(X_trainB_XGB_RF.shape)\n",
    "print(X_testB.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing updated dataframe to XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Time for Random Forest with XG BOOST:  0.22909212112426758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "XGB_Classifier_RF = XGBClassifier(base_score=0.3, n_estimators=5)\n",
    "XGB_Classifier_RF.fit(X_trainB_XGB_RF, Y_trainB_XGB_RF)\n",
    "print()\n",
    "\n",
    "t2=time.time()\n",
    "print (\"Training Time for Random Forest with XG BOOST: \", t2-t1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing new XG Boost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Time for Random Forest with XG BOOST:  0.005087375640869141\n",
      "\n",
      "\n",
      "============================== Random Forest + XG Boost Model Evaluation ==============================\n",
      "\n",
      "Cross Validation Mean Score:\n",
      " 0.9912713222647399\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9940476190476191\n",
      "\n",
      "Confusion matrix:\n",
      " [[1177    0]\n",
      " [  15 1328]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly  0.98741611 1.00000000 0.99366821      1177\n",
      "      normal  1.00000000 0.98883098 0.99438413      1343\n",
      "\n",
      "   micro avg  0.99404762 0.99404762 0.99404762      2520\n",
      "   macro avg  0.99370805 0.99441549 0.99402617      2520\n",
      "weighted avg  0.99412252 0.99404762 0.99404975      2520\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "Y_testB_XGB_RF_pred = XGB_Classifier_RF.predict(X_testB_XGB_RF)\n",
    "t2=time.time()\n",
    "print (\"Prediction Time for Random Forest with XG BOOST: \", t2-t1)\n",
    "print()\n",
    "scores_XGB_RF = cross_val_score(XGB_Classifier_RF, X_testB_XGB_RF, Y_testB_XGB_RF, cv=10)\n",
    "accuracy_XGB_RF = metrics.accuracy_score(Y_testB_XGB_RF, Y_testB_XGB_RF_pred)\n",
    "confusion_matrix_XGB_RF = metrics.confusion_matrix(Y_testB_XGB_RF,Y_testB_XGB_RF_pred)\n",
    "classification_XGB_RF = metrics.classification_report(Y_testB_XGB_RF,Y_testB_XGB_RF_pred, digits=8)\n",
    "print()\n",
    "print('============================== {} Model Evaluation =============================='.format('Random Forest + XG Boost'))\n",
    "print()\n",
    "print (\"Cross Validation Mean Score:\" \"\\n\", scores_XGB_RF.mean())\n",
    "print()\n",
    "print (\"Model Accuracy:\" \"\\n\", accuracy_XGB_RF)\n",
    "print()\n",
    "print(\"Confusion matrix:\" \"\\n\", confusion_matrix_XGB_RF)\n",
    "print()\n",
    "print(\"Classification report:\" \"\\n\", classification_XGB_RF) \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest + Decsion tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of number of FP: 10077\n",
      "(10077, 35)\n",
      "(2520, 34)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"models = []\n",
    "models.append(('Naive Baye Classifier', BNB_Classifier))\n",
    "models.append(('Decision Tree Classifier', DTC_Classifier))\n",
    "models.append(('XG Boost Classifier', XGB_Classifier))\n",
    "models.append(('Random Forest Classifier', RandomForest_Classifier))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "##USING DECISION TREE TO PREDICT PREVIOUS VALUES\n",
    "X_testB_DCT_RF = X_testB.copy()\n",
    "Y_testB_DCT_RF = Y_testB.copy()\n",
    "X_trainB_DCT_RF = X_trainB.copy()\n",
    "Y_trainB_DCT_RF = Y_trainB.copy()\n",
    "finalPred= genPredRow(Y_trainB_DCT_RF, models[1][1].predict(X_trainB_DCT_RF))\n",
    "print(\"Size of number of FP:\", finalPred.size) \n",
    "\n",
    "finalPredTest = genPredRow(Y_testB_DCT_RF, models[1][1].predict(X_testB_DCT_RF))\n",
    "\n",
    "X_trainB_DCT_RF['prevPred'] = np.array(finalPred)\n",
    "X_testB_DCT_RF['prevPred'] = np.array(finalPredTest)\n",
    "print(X_trainB_DCT_RF.shape)\n",
    "print(X_testB.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## passing updated dataframe to Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Time for Random Forest with XG BOOST:  0.18131065368652344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DTC_Classifier_RF = tree.DecisionTreeClassifier(criterion='gini',max_depth=2, random_state=10)\n",
    "DTC_Classifier_RF.fit(X_trainB_DCT_RF, Y_trainB_DCT_RF)\n",
    "print()\n",
    "\n",
    "t2=time.time()\n",
    "print (\"Training Time for Random Forest with XG BOOST: \", t2-t1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing new Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Time for Random Forest with XG BOOST:  0.004648923873901367\n",
      "\n",
      "\n",
      "============================== Random Forest + Decision Model Evaluation ==============================\n",
      "\n",
      "Cross Validation Mean Score:\n",
      " 0.9912713222647399\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9940476190476191\n",
      "\n",
      "Confusion matrix:\n",
      " [[1177    0]\n",
      " [  15 1328]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly  0.98741611 1.00000000 0.99366821      1177\n",
      "      normal  1.00000000 0.98883098 0.99438413      1343\n",
      "\n",
      "   micro avg  0.99404762 0.99404762 0.99404762      2520\n",
      "   macro avg  0.99370805 0.99441549 0.99402617      2520\n",
      "weighted avg  0.99412252 0.99404762 0.99404975      2520\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "Y_testB_DCT_RF_pred = XGB_Classifier_RF.predict(X_testB_DCT_RF)\n",
    "t2=time.time()\n",
    "print (\"Prediction Time for Random Forest with XG BOOST: \", t2-t1)\n",
    "print()\n",
    "scores_DCT_RF = cross_val_score(XGB_Classifier_RF, X_testB_DCT_RF, Y_testB_DCT_RF, cv=10)\n",
    "accuracy_DCT_RF = metrics.accuracy_score(Y_testB_DCT_RF, Y_testB_DCT_RF_pred)\n",
    "confusion_matrix_DCT_RF = metrics.confusion_matrix(Y_testB_DCT_RF,Y_testB_DCT_RF_pred)\n",
    "classification_DCT_RF = metrics.classification_report(Y_testB_DCT_RF,Y_testB_DCT_RF_pred, digits=8)\n",
    "print()\n",
    "print('============================== {} Model Evaluation =============================='.format('Random Forest + Decision'))\n",
    "print()\n",
    "print (\"Cross Validation Mean Score:\" \"\\n\", scores_DCT_RF.mean())\n",
    "print()\n",
    "print (\"Model Accuracy:\" \"\\n\", accuracy_DCT_RF)\n",
    "print()\n",
    "print(\"Confusion matrix:\" \"\\n\", confusion_matrix_DCT_RF)\n",
    "print()\n",
    "print(\"Classification report:\" \"\\n\", classification_DCT_RF) \n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
